{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sequence to sequence example in Keras (character-level).\\n\\nThis script demonstrates how to implement a basic character-level\\nsequence-to-sequence model. We apply it to translating\\nshort English sentences into short French sentences,\\ncharacter-by-character. Note that it is fairly unusual to\\ndo character-level machine translation, as word-level\\nmodels are more common in this domain.\\n\\n# Summary of the algorithm\\n\\n- We start with input sequences from a domain (e.g. English sentences)\\n    and correspding target sequences from another domain\\n    (e.g. French sentences).\\n- An encoder LSTM turns input sequences to 2 state vectors\\n    (we keep the last LSTM state and discard the outputs).\\n- A decoder LSTM is trained to turn the target sequences into\\n    the same sequence but offset by one timestep in the future,\\n    a training process called \"teacher forcing\" in this context.\\n    Is uses as initial state the state vectors from the encoder.\\n    Effectively, the decoder learns to generate `targets[t+1...]`\\n    given `targets[...t]`, conditioned on the input sequence.\\n- In inference mode, when we want to decode unknown input sequences, we:\\n    - Encode the input sequence into state vectors\\n    - Start with a target sequence of size 1\\n        (just the start-of-sequence character)\\n    - Feed the state vectors and 1-char target sequence\\n        to the decoder to produce predictions for the next character\\n    - Sample the next character using these predictions\\n        (we simply use argmax).\\n    - Append the sampled character to the target sequence\\n    - Repeat until we generate the end-of-sequence character or we\\n        hit the character limit.\\n\\n# Data download\\n\\nEnglish to French sentence pairs.\\nhttp://www.manythings.org/anki/fra-eng.zip\\n\\nLots of neat sentence pairs datasets can be found at:\\nhttp://www.manythings.org/anki/\\n\\n# References\\n\\n- Sequence to Sequence Learning with Neural Networks\\n    https://arxiv.org/abs/1409.3215\\n- Learning Phrase Representations using\\n    RNN Encoder-Decoder for Statistical Machine Translation\\n    https://arxiv.org/abs/1406.1078\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Sequence to sequence example in Keras (character-level).\n",
    "\n",
    "This script demonstrates how to implement a basic character-level\n",
    "sequence-to-sequence model. We apply it to translating\n",
    "short English sentences into short French sentences,\n",
    "character-by-character. Note that it is fairly unusual to\n",
    "do character-level machine translation, as word-level\n",
    "models are more common in this domain.\n",
    "\n",
    "# Summary of the algorithm\n",
    "\n",
    "- We start with input sequences from a domain (e.g. English sentences)\n",
    "    and correspding target sequences from another domain\n",
    "    (e.g. French sentences).\n",
    "- An encoder LSTM turns input sequences to 2 state vectors\n",
    "    (we keep the last LSTM state and discard the outputs).\n",
    "- A decoder LSTM is trained to turn the target sequences into\n",
    "    the same sequence but offset by one timestep in the future,\n",
    "    a training process called \"teacher forcing\" in this context.\n",
    "    Is uses as initial state the state vectors from the encoder.\n",
    "    Effectively, the decoder learns to generate `targets[t+1...]`\n",
    "    given `targets[...t]`, conditioned on the input sequence.\n",
    "- In inference mode, when we want to decode unknown input sequences, we:\n",
    "    - Encode the input sequence into state vectors\n",
    "    - Start with a target sequence of size 1\n",
    "        (just the start-of-sequence character)\n",
    "    - Feed the state vectors and 1-char target sequence\n",
    "        to the decoder to produce predictions for the next character\n",
    "    - Sample the next character using these predictions\n",
    "        (we simply use argmax).\n",
    "    - Append the sampled character to the target sequence\n",
    "    - Repeat until we generate the end-of-sequence character or we\n",
    "        hit the character limit.\n",
    "\n",
    "# Data download\n",
    "\n",
    "English to French sentence pairs.\n",
    "http://www.manythings.org/anki/fra-eng.zip\n",
    "\n",
    "Lots of neat sentence pairs datasets can be found at:\n",
    "http://www.manythings.org/anki/\n",
    "\n",
    "# References\n",
    "\n",
    "- Sequence to Sequence Learning with Neural Networks\n",
    "    https://arxiv.org/abs/1409.3215\n",
    "- Learning Phrase Representations using\n",
    "    RNN Encoder-Decoder for Statistical Machine Translation\n",
    "    https://arxiv.org/abs/1406.1078\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples =10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'data5000delspace.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 4999\n",
      "Number of unique input tokens: 3132\n",
      "Number of unique output tokens: 3010\n",
      "Max sequence length for inputs: 53\n",
      "Max sequence length for outputs: 57\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from keras.models import load_model\n",
    "model_name = 's2slstm.h5'\n",
    "\n",
    "if os.path.isfile(model_name):\n",
    "    print('file exists')\n",
    "    #model = load_model(model_name)\n",
    "    \n",
    "    # layers[0...4]= 0:encoder_input, 1:decoder_input, 2:encoder_lstm, 3:decoder_lstm, 4:decoder_output\n",
    "    #encoder_inputs = model.layers[0]\n",
    "    #encoder = model.layers[2]\n",
    "    #decoder_lstm = model.layers[3]\n",
    "    #decoder_dense = model.layers[4]\n",
    "    \n",
    "    #encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    #encoder_states = [state_h, state_c]\n",
    "    \n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens),name='encoder_input')\n",
    "    encoder = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens),name='decoder_input')\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_output')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.load_weights(model_name)\n",
    "\n",
    "else:\n",
    "    print('file not exists')\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens),name='encoder_input')\n",
    "    encoder = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens),name='decoder_input')\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_output')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    # Run training\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "    # Save model\n",
    "    model.save_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x000001FE190E2EB8>\n"
     ]
    }
   ],
   "source": [
    "print(decoder_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trainable': True, 'activity_regularizer': None, 'supports_masking': True, 'stateful': False, 'name': 'decoder_output', 'bias_constraint': None, 'kernel_constraint': None, '_built': True, '_outbound_nodes': [], '_non_trainable_weights': [], '_initial_weights': None, '_per_input_losses': {}, 'use_bias': True, 'bias_initializer': <keras.initializers.Zeros object at 0x000001FE190FF208>, 'input_spec': InputSpec(min_ndim=2, axes={-1: 256}), '_trainable_weights': [<tf.Variable 'decoder_output/kernel:0' shape=(256, 3010) dtype=float32_ref>, <tf.Variable 'decoder_output/bias:0' shape=(3010,) dtype=float32_ref>], 'bias': <tf.Variable 'decoder_output/bias:0' shape=(3010,) dtype=float32_ref>, 'kernel': <tf.Variable 'decoder_output/kernel:0' shape=(256, 3010) dtype=float32_ref>, 'kernel_regularizer': None, 'activation': <function softmax at 0x000001FBB9E48E18>, '_per_input_updates': {}, '_inbound_nodes': [<keras.engine.base_layer.Node object at 0x000001FE1A2A8CC0>], '_updates': [], 'kernel_initializer': <keras.initializers.VarianceScaling object at 0x000001FE190FF128>, '_losses': [], 'units': 3010, 'bias_regularizer': None}\n"
     ]
    }
   ],
   "source": [
    "print(decoder_dense.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: ä¸­å›½ç§»åŠ¨è¥é”€è¡Œæ¥å‘å±•æŠ¥å‘Šalink\n",
      "Decoded sentence: å»è¿‡é‚£ä¹ˆå¤šæ¬¡ï¼Œä»æ¥æ²¡è§è¿‡\n",
      "\n",
      "-\n",
      "Input sentence: å°é©¬ä¹Ÿç–¯ç‹‚------åœ°ä½ä¹‹äº‰ã€‚\n",
      "Decoded sentence: å°±æ˜¯ä¸€å¤©ï¼Œåˆä¸€ä¸ªäººï¼Œæˆ‘æ— èŠå¾—\n",
      "\n",
      "-\n",
      "Input sentence: é‚£äº›å¹´ï¼Œæˆ‘ä»¬ä¸€èµ·å·çœ‹è¿‡çš„ç”µè§†ã€‚ã€Œæš´èµ°æ¼«ç”»ã€\n",
      "Decoded sentence: çœŸä¸æ„§æ˜¯è¿™ä¹ˆèµ°å‡ºæ¥çš„çˆ¹Â·Â·Â·Â·Â·Â·Â·Â·\n",
      "\n",
      "-\n",
      "Input sentence: åŒ—äº¬çš„å°çº¯æ´ä»¬ï¼Œå‘¨æ—¥è§ã€‚#ç¡¬æ±‰æ‘†æ‹æ¸…çº¯ç…§#\n",
      "Decoded sentence: çœ‹åˆ°çš„å­©å­å †ï¼šæ¡é‡Œæ˜¯æœ€å¥³äººçš„\n",
      "\n",
      "-\n",
      "Input sentence: è¦æ˜¯è¿™ä¸€å¹´å“­æ³£çš„ç†ç”±ä¸å†æ˜¯éš¾è¿‡è€Œæ˜¯æ„ŸåŠ¨ä¼šå¤šä¹ˆå¥½\n",
      "Decoded sentence: æˆ‘å·²ç»å¿«æ„ŸåŠ¨å¾—å“­äº†ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å¯¹äºå›½å†…åŠ¨æ¼«ç”»ä½œè€…å¼•ç”¨å·¥ç¬”ç´ æçš„ä¸€äº›ä¸ªäººæ„è§ã€‚\n",
      "Decoded sentence: äººç”Ÿçš„æ˜¯å¤šå°‘ï¼Œé’±çš„äººå‡º\n",
      "\n",
      "-\n",
      "Input sentence: çŒ«å’ªä¿é•–æœ€èµäº†ï¼ä½ ä»¬çœ‹æ‡‚äº†å—ï¼Ÿï¼ï¼ˆæ¥è‡ªï¼š9gagï¼‰\n",
      "Decoded sentence: è¦æ±‚åé›·å°±æ˜¯è¦ä¸cwicneÂ·Â·\n",
      "\n",
      "-\n",
      "Input sentence: è«æ„å’Œæ‰€æœ‰äººå¼€äº†ä¸€ä¸ªç©ç¬‘â€”â€”å…¶å®ï¼Œå¥¹æ˜¯ä¼šæ­£å¸¸å”±æ­Œçš„â€¦â€¦\n",
      "Decoded sentence: æ˜¯ï¼Œæˆ‘çš„å¤©å‘Šæˆ‘å°æˆ‘ï¼Œè€å´å°±ä¸‹äº†å›åºŠã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä½ è§è¿‡çš®å¡ä¸˜å–æ°´çš„æ ·å­å—ï¼Ÿ\n",
      "Decoded sentence: å°äº’ä½ çš„ç²‰ä¸è‚¯å®šå¤§\n",
      "\n",
      "-\n",
      "Input sentence: å¦‚æœæœ‰ä¸ªäººèƒ½è®©ä½ å¿˜æ‰è¿‡å»ï¼Œé‚£TAå¾ˆå¯èƒ½å°±æ˜¯ä½ çš„æœªæ¥ã€‚\n",
      "Decoded sentence: ä¸‹é¢çš„äº‹å„¿ä»¬æœ‰å¿…è¦å¤šä¹ˆå¤šå¤§ç‹ä¼šï¼\n",
      "\n",
      "-\n",
      "Input sentence: æˆ‘åœ¨åŒ—äº¬ï¼Œ24å²ï¼Œæƒ³å»é©¬å°”ä»£å¤«ï¼Œä¸€ä¸ªäººã€‚\n",
      "Decoded sentence: è¿™å¤ªå¯ä»¥äº†ï¼Œå“ªé‡Œæ²¡æœ‰é«˜å‘¢ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: å“¥ä½ è¿˜è·³ä¸è·³æ¥¼äº†ï¼Ÿæˆ‘ä»¬è¦ä¸‹ç­å•Šï¼\n",
      "Decoded sentence: æˆ‘æƒ³å»å¾ˆå¤šï¼Œé’±å°±æ˜¯æˆ‘ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: é¾™ç”Ÿé¾™ï¼Œå‡¤ç”Ÿå‡¤ï¼Œæ˜¯ä¸ªå–µå’ªå®ƒå°±èŒã€‚\n",
      "Decoded sentence: è€çˆ·å­ä¸ä¼šé•¿å¤§ï¼Œä½ å¿ƒä½ å‘¢ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: ä»èƒšèƒæœŸå¼€å§‹çš„é¢éƒ¨ç‰¹å¾æ¼”å˜è¿‡ç¨‹\n",
      "Decoded sentence: çœŸå¿ƒä½©æœå‡¯å­çš„ç²¾ç¥ï¼\n",
      "\n",
      "-\n",
      "Input sentence: æœ¬å±Šè½®å€¼ä¸»å¸­ç‹çŸ³è‡´å¼€å¹•è¯ã€‚è®²60å²ä¸Šå“ˆä½›ã€‚\n",
      "Decoded sentence: æ˜¯å•Šï¼Œä½ ï¼Œè¿™ä¹ˆçº¿æˆ‘ï¼Œå¹¸ç¦æˆ‘ç”Ÿæ—¥åœ¨ä¸­\n",
      "\n",
      "-\n",
      "Input sentence: éå¸¸ä¸å–œæ¬¢åŒ—äº¬ç°åœ¨çš„å¤©æ°”â€¦â€¦éå¸¸â€¦â€¦\n",
      "Decoded sentence: æˆ‘ä¹Ÿä¸å–œæ¬¢é‚£ç§åˆå†·åˆä¸‹é›¨çš„å¤©æ°”äº†ï¼\n",
      "\n",
      "-\n",
      "Input sentence: æˆ‘ç¬¬ä¸€æ¬¡åé£æœºæ˜¯è¿›å®‰è¾¾ä¿¡çš„å…¥èŒåŸ¹è®­ï¼Œåœ¨æ·±åœ³ã€‚ä½ ä»¬å“ªï¼Ÿ\n",
      "Decoded sentence: å“ˆå“ˆï¼Œè¿™æ˜¯æ€ä¹ˆæ ·çš„èƒ½è¶Šåšè¶Šæ¥ï¼Œæ²¡æœ‰æˆ‘æœ‰ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: äººç”Ÿå¦‚æˆï¼Œå…¨é æ¼”æŠ€ã€‚å°å—å“åäº†ã€‚\n",
      "Decoded sentence: äººç”Ÿå¦‚æˆï¼Œå…¨é æ¼”æŠ€ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä¸ºä»€ä¹ˆè¿™ä¸–ä¸Šä¼šæœ‰äººä»¥åˆéš¾ä»–äººä¸ºä¹å‘¢ï¼Ÿ\n",
      "Decoded sentence: æ˜¯ä¸èƒ½æ­£çš„åœ°ä¸¾ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ç®—äº†ç®—äº†ï¼Œæˆ‘çœ‹å‡ºæ¥äº†ï¼Œä½ ä»¬éƒ½æƒ³çœ‹ç”·äººï¼ä¸Šå¼ ç¾ç”·å›¾ã€‚\n",
      "Decoded sentence: å¤šæ”¾ç‚¹ç”·æ¨¡çš„ç…§ç‰‡çœ‹çœ‹\n",
      "\n",
      "-\n",
      "Input sentence: å·æ‹æ—¶è¢«å–µæ˜Ÿäººå‘ç°äº†ã€‚ï¼\\3/\n",
      "Decoded sentence: ä»¥å‰åœ¨ç‰©æµå…¬å¸ï¼Œä¸¾è¡Œè¿‡é©¾é©¶å‘˜æ»šè½®èƒæ¯”èµ›ï¼Œæ‹äº†ç…§ç‰‡ï¼ŒæŒºæœ‰æ„æ€\n",
      "\n",
      "-\n",
      "Input sentence: çœ‹çœ‹ä½ çš„åå­—åœ¨å¤ä»£æ˜¯ä»€ä¹ˆèŒä¸šï¼Œå¤ªè®©äººå´©æºƒäº†ã€‚\n",
      "Decoded sentence: äººç”Ÿå¦‚æˆï¼Œå…¨é æ¼”æŠ€ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å±…ç„¶æŠŠWindowsPhone8å†™æˆWin8äº†â€¦â€¦è¦ä¸¥è°¨å•Š\n",
      "Decoded sentence: ä¸çŸ¥é“ä¸ºä»€ä¹ˆæœ‰è¿™æ ·ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: ç™¾åˆçœŸé¦™å•Šï¼é€ç»™å›å®¶è·¯ä¸Šçš„äººä»¬æ˜å¤©åå¤©å°±ä¸è¡Œäº†ï¼\n",
      "Decoded sentence: è¿˜æ˜¯ä¸ªå¯çˆ±çš„å°èƒ–çº¸\n",
      "\n",
      "-\n",
      "Input sentence: åˆ˜ç¿”é¢„ç®—æ‘”å€’ï¼æ— ç¼˜åŠå†³èµ›ï¼ä¸»æŒäººå“­äº†ã€‚\n",
      "Decoded sentence: æ˜¯çš„æ˜¯ä¸€ä¸ªå°æ€»è¦ä»€ä¹ˆçš„æ—¶å€™äº†ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: è°èº«è¾¹æ²¡å‡ ä¸ªèƒ½åŠå¤§äº‹çš„æœ‹å‹ï¼Ÿ\n",
      "Decoded sentence: å¥½æƒ³åƒï¼Œå¯æ˜¯æˆ‘å®¶é‡Œæ²¡æœ‰å‘¢ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: ä¸€ä½å¦ˆå¦ˆå°†å¥¹å››å²å„¿å­çš„æ¶‚é¸¦åšæˆäº†çœŸå®çš„æ¯›ç»’ç©å…·\n",
      "Decoded sentence: å–œæ¬¢ç¬¬ä¸‰å¼ å›¾ã€‚æ˜äº®çš„æ—¶å€™åŠ›ç‚¹äº†\n",
      "\n",
      "-\n",
      "Input sentence: ç«Ÿç„¶ä¸‹é›ªäº†ï¼Œä¸å–œæ¬¢å†¬å¤©ï¼Œå¤©æ°”ä½•æ—¶æ‰å˜æš–å•Šã€‚\n",
      "Decoded sentence: å½“ç„¶åšé»‘äº†ï¼šæˆ‘å¯ä»¥æ…¢æï¼Œï¼Œåæ˜¯åº”è¯¥å¥åº·ã€\n",
      "\n",
      "-\n",
      "Input sentence: å›°æ‰°æˆ‘å¤šå¹´çš„é—®é¢˜ç»ˆäºå¾—è§£äº†ã€‚\n",
      "Decoded sentence: å“å“Ÿå–‚ã€‚ç«‹é©¬çŸ³åŒ–äº†ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å¤§å­¦ç”Ÿä¸€å®šè¦çœ‹çš„ä¸€åˆ†é’Ÿï¼Œå®ƒèƒ½è®©ä½ å¥‹æ–—ä¸€è¾ˆå­alink\n",
      "Decoded sentence: è¿™æ˜¯å“ªé‡Œé¢å¾—é©¬å—ï¼Ÿæˆ‘ä»¬å‘¢ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: #ç±³å§ç§€å›¾#æœˆåº•äº†ï¼Œæ•¢è¯´å‡ºä½ æ‰‹æœºè¿˜æœ‰å¤šå°‘æµé‡ä¹ˆï¼Ÿ\n",
      "Decoded sentence: è¿™ä¸ªå›¾ç‰‡æ˜¯è°ç…§çš„å•Šï¼ŒçœŸæ˜¯ç»å•Š\n",
      "\n",
      "-\n",
      "Input sentence: æˆ‘æ“¦ï¼è¿™ä¹ˆå¤šäººæ¥çœ‹æˆ‘ï¼\n",
      "Decoded sentence: æ˜¯çš„æ ·çš„ï¼åº”è¯¥æ˜¯é‚£ä¹ˆçš„å“‡ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: å„ä½éƒ½åˆ°äº†å—ï¼Ÿæ·±åœ³ä¸€ä¼šè§å“ˆï¼šï¼‰ï¼‰\n",
      "Decoded sentence: å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆã€‚åšäº†ä¸‰å¹´çºªå¾‹å§”å‘˜æ²¡åšè¿‡æ³¢ğŸ˜ğŸ˜\n",
      "\n",
      "-\n",
      "Input sentence: å¦‚æœæœ‰äººç…®è¿™ä¸ªæ±¤ç»™ä½ å–ï¼Œä½ ä¼šæ„ŸåŠ¨å—ï¼Ÿ\n",
      "Decoded sentence: æ˜¯ä¸èƒ½æ‹çš„ç§˜å¯†ï¼Œå°±æ˜¯ä¸ªå‘Šè¯‰ä½ éƒ½ä¸è®¤è¯†\n",
      "\n",
      "-\n",
      "Input sentence: ä¸Šä¼ äº†23å¼ ç…§ç‰‡åˆ°â€œå¾®ç›¸å†Œâ€ã€‚alink\n",
      "Decoded sentence: å¥½æƒ³çœ‹ï¼Œè¿ä¸Šé¸¡çš„éƒ½æœ‰ç‚¹æ²¹ï¼Œè¿™ç§ï¼Œè®©æˆ‘ä»¬ç„¶\n",
      "\n",
      "-\n",
      "Input sentence: çœ‹è§æœ‰é»‘ç‚¹çš„è¦æ³¨æ„ä¼‘æ¯äº†ã€‚\n",
      "Decoded sentence: å¤§å®¶ä¸€å—é¢„æµ‹éƒ½è¯´æœ‰å‘æ„ç”²è½¦çš„æ˜å¹´çš„è¯¾ç»ƒåŒä¸ª\n",
      "\n",
      "-\n",
      "Input sentence: è‹¥æ…ˆå–„ä¸é€æ˜ï¼Œåˆ™ææ¬¾æ— æ„ä¹‰ã€‚\n",
      "Decoded sentence: ä¸­å›½é»„é‡‘å¹´ä»£çš„feelã€‚çœŸçš„ä¸ä¸€æ ·ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: æˆç†Ÿçš„æœ€å¤§å¥½å¤„æ˜¯ï¼šä»¥å‰å¾—ä¸åˆ°çš„ï¼Œç°åœ¨ä¸æƒ³è¦äº†ã€‚\n",
      "Decoded sentence: çœŸæƒ³çœ‹ä¸‹ä»–çš„æ­£é¢æ˜¯æ€ä¹ˆæ ·çš„\n",
      "\n",
      "-\n",
      "Input sentence: ç¼–ç»‡å’Œä»¿æ—§çš„é£æ ¼ï¼Œçœ‹èµ·æ¥å¾ˆæœ‰è´¨æ„Ÿ\n",
      "Decoded sentence: å¦‚æœè¿™ä¸ªæ˜Ÿçƒéƒ½è®¤è¯†\n",
      "\n",
      "-\n",
      "Input sentence: å¬åˆ°è¿™å‘¨è¦è¿ä¸Š7å¤©çš„æ¶ˆæ¯åï¼Œæˆ‘çªç„¶æ„è¯†åˆ°ã€‚\n",
      "Decoded sentence: å“å“Ÿå–‚ã€‚ç«‹é©¬çŸ³åŒ–äº†ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: æ…¢é•œå¤´å›æ”¾ç‹—ç‹—çœ‹åˆ°é£Ÿç‰©çš„å¯çˆ±ååº”ï¼alink\n",
      "Decoded sentence: å¥½æƒ³åƒä¸€èµ·å¯ä»¥å–åˆ°wareæ‰‹æœºé‡Œçš„å­¦eäº†ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä¸ªäººç»éªŒï¼Œæ™®é€šè¯è¿‡äºæ ‡å‡†çš„äººä¸€èˆ¬å¹²ä¸äº†ä»€ä¹ˆå¤§äº‹ã€‚\n",
      "Decoded sentence: æ²¡äº‹ï¼Œè¿™å°±æ˜¯è·å…°ï¼Œæ¢ä¸ªä¸»å¸…ï¼Œ2014å†çœ‹éƒé‡‘é¦™ç»½æ”¾ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å–µæ˜Ÿäººä¸ªä¸ªéƒ½æ˜¯æ­¦æ—é«˜æ‰‹ï¼\n",
      "Decoded sentence: å“ˆå“ˆï¼Œè¿™æ˜¯çœŸçš„çˆ±ï¼Œæˆ‘å¸…å•Šï¼\n",
      "\n",
      "-\n",
      "Input sentence: 2012åœ°çƒä¸ä¼šæ¯ç­ï¼Œå› ä¸ºå¤šå•¦Aæ¢¦å‘Šè¯‰æˆ‘ä»¬ä»–æ˜¯ä»2070å¹´æ¥çš„ã€‚\n",
      "Decoded sentence: è¦æ˜¯çº¹èº«å°±çº¹ä¸ªå“†å•¦Aæ¢¦\n",
      "\n",
      "-\n",
      "Input sentence: #è™æ‰‘è¯é¢˜#è°æ˜¯ä½ å¿ƒä¸­å¤–è²Œæœ€å¸…æ°”çš„æ•™ç»ƒï¼Ÿalink\n",
      "Decoded sentence: è¿™æ˜¯ä¸ªäººï¼Œè´Ÿçˆ±èµ°å‡ºäººï¼Œæˆ–è®¸æ˜¯è¿™äººã€‚è®¤è¿™èº«å¿ƒçš„å¾ˆå¶\n",
      "\n",
      "-\n",
      "Input sentence: è‹¹æœä¸è¦åªå‰Šä¸€åŠå¥½ä¸å¥½ï¼ä½ ä»¬è€ƒè™‘è¿‡è‹¹æœçš„æ„Ÿå—å˜›ï¼\n",
      "Decoded sentence: çš„ç¡®ä¼¤ç¾ã€‚æ‰‹æœºæ¢çš„å¥³å„¿ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: è½¬çœ¼ï¼Œä»–èµ°äº†16å¹´ã€‚å¦‚æœï¼Œä»–è¿˜æ´»ç€â€¦â€¦\n",
      "Decoded sentence: è¿™æ ·çš„è¯æˆ‘ä»¬éƒ½å¯ä»¥é—®ï¼Œå”¯ç‹¬ä½ ä¸èƒ½é—®ï¼\n",
      "\n",
      "-\n",
      "Input sentence: alinkè®²å¥½å…¬å­å’Œåå…¬å­çš„æ–‡ç« ï¼Œä¸é”™ã€‚å‡¤å‡°ç½‘ã€‚\n",
      "Decoded sentence: å¤šè¿™å°±å¯¹ï¼Œå¯¹æˆ‘èµ·æ¥åƒè‰ï¼\n",
      "\n",
      "-\n",
      "Input sentence: æ¨æ€¡çœŸçš„å¥½åƒé©¬å•Šï¼å¥½æƒ³å–‚å¥¹åƒè‰ï¼\n",
      "Decoded sentence: åªè¦è‚¯èŠ±å¿ƒæ€ä»€ä¹ˆå¤æ‚çš„éƒ½è§‰å¾—åƒ\n",
      "\n",
      "-\n",
      "Input sentence: ã€æ²»æ„ˆç³»å›¾ç‰‡ã€‘åˆåˆ°äº†æ¯•ä¸šå­£â€”â€”è¿™ä¹ˆæœ‰çˆ±çš„æ¯•ä¸šç…§ä½ ä»¬è§è¿‡å—ï¼Ÿ\n",
      "Decoded sentence: æˆ‘ä¹Ÿå¤ªæœ‰æ„æ€äº†ä¸€å¥è¯çš„ã€‚é©¬å­è¿™ä¹ˆå¤šå‘¢ï¼Œè¿™å¥çˆ¸æˆ‘ä»¬è€ä¸€ä¸‹\n",
      "\n",
      "-\n",
      "Input sentence: ç§‘æ™®è´´ï¼šã€Šå¤§æ—å’Œå°æ—ã€‹å‰§ç…§\n",
      "Decoded sentence: çœ‹ç€å¥½å“äººå•Šï¼æœ‰æ²¡æœ‰äººåŒæ„Ÿï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: å¦å¤–ä¸€ä¸ªåæ¶ˆæ¯ï¼Œå·´æ©æ–¯ç»­çº¦å¿«èˆ¹ï¼Œå­©å­ä»¬ï¼Œå’±åˆæ²¡æˆäº†ã€‚\n",
      "Decoded sentence: æ²¡æœ‰æ‰€è°“ã€‚è¢«è¿‡ä½ ä¹Ÿåšè‚‰è¥¿æ€§ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: è¿‡å»æˆ‘ä»¬å†ä¹Ÿå›ä¸å»äº†ï¼Œ\n",
      "Decoded sentence: æˆ‘ä¹Ÿåœ¨å¤©æ²³åŸé™„è¿‘å“ˆå“ˆä¸çŸ¥é“æœ‰æœ¨æœ‰æœºä¼šçœ‹åˆ°ä½ \n",
      "\n",
      "-\n",
      "Input sentence: ä¸€ç¾¤åƒåœ¾çš„åˆ¶é€ è€…ï¼Œå½“ç„¶ä¹ŸåŒ…æ‹¬æˆ‘è‡ªå·±ã€‚\n",
      "Decoded sentence: åº”è¯¥æ˜¯ä¸€ç¾¤èµ„æºçš„é—å¼ƒè€…\n",
      "\n",
      "-\n",
      "Input sentence: èµ°è¿‘ç§‘å­¦ï¼šç¥å†œæ¶é‡é¦™è•‰ã€‚å›½å¤–åˆç§°æ­»äººæ‰‹æŒ‡\n",
      "Decoded sentence: èƒ½åƒå—â€¦â€¦â€¦â€¦å¥½æƒ³åâ€¦â€¦\n",
      "\n",
      "-\n",
      "Input sentence: ä¸è¦æ‹å®¶ï¼åˆè¦å¼€å§‹è®­ç»ƒå•¦ï¼ä¸æƒ³å›å®¶ï¼Œä¸€ç‚¹ä¹Ÿä¸æƒ³\n",
      "Decoded sentence: ä¸æ˜¯ç”¨äº†ï¼Œå›½å®¶çš„è¯•é™¢â€¦â€¦\n",
      "\n",
      "-\n",
      "Input sentence: #éƒ‘åœ¨æé†’åƒæ—©é¤#æ²¡å¿˜äº†åƒæ—©é¥­å§ï¼Ÿé¤æ¡Œä¸Šè¿™æ®µæ–‡å­—å‡ºè‡ªå“ªéƒ¨ä½œå“ï¼Ÿ\n",
      "Decoded sentence: å¤§å”çš„æ—©é¤å¥½æœ‰è¥å…»ï¼\n",
      "\n",
      "-\n",
      "Input sentence: ç”·å­å› å¥³å„¿å“­é—¹ä¸€è„šå°†å…¶è¸¢æ­»alink\n",
      "Decoded sentence: å°å­©å“­é—¹çš„ç¡®å¾ˆçƒ¦äººåªèƒ½è¯´è¿™ä½çˆ¶äº²ç‚¹èƒŒç»™è¸¢æ­»äº†\n",
      "\n",
      "-\n",
      "Input sentence: å½“ä½ è§‰å¾—ç”Ÿæ´»æ²¡æ„æ€çš„æ—¶å€™ã€‚(è½¬)\n",
      "Decoded sentence: ä¼šä¸ä¼šæ˜¯â€œå®‰ç¥â€å§ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: ç™¾åº¦å®˜æ–¹å¾®åšå³å°†ä¸Šçº¿ï¼Œæ•¬è¯·æœŸå¾…ï¼\n",
      "Decoded sentence: ä¸­å›½æœç´¢å¼•æ“çš„å¤§ä½¬ä¹Ÿæ¥å¾®åšäº†ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: é•¿æ˜¥æŸç¿ å›­å°åŒºç»¿åŒ–æ¤ç‰©ä¹‹ä¸€ï¼šä¼å½¢ç´«èŠ±ï¼ŒçŒæœ¨ï¼Œç§‘å±ç§ï¼Ÿ\n",
      "Decoded sentence: ä½ æ„æ€æ˜¯ä¸€ä¸ªå›¾ç‰‡æ˜¯åœ¨æœ›å¹´è¯†è¿‡å¯èƒ½çš„å›äº‹çš„åœ°ä¸ä¸€ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: #NBAæ€»å†³èµ›#çƒ­ç«å‡»è´¥é©¬åˆºï¼Œå«å†•æˆåŠŸã€‚\n",
      "Decoded sentence: è€å…µæ°¸è¿œä¸æ­»ã€‚è™å¿ƒçš„ç¬¬å…­åœºï¼\n",
      "\n",
      "-\n",
      "Input sentence: æ®è¯´ï¼Œå¼ºè¿«ç—‡çš„ç«¥é‹çœ‹å®Œä¹‹åå¾ˆéš¾å—ã€‚ã€Œè½¬ã€\n",
      "Decoded sentence: äººæ°‘æˆ˜å£«ã€‚åšæ—¶è‡ªå‡ ä¸ªé‚£äº›çœ‹\n",
      "\n",
      "-\n",
      "Input sentence: è°æ˜¯è°çš„å¦‚èŠ±ç¾çœ·ï¼Œè°é”™è¿‡äº†è°çš„ä¼¼æ°´æµå¹´ã€‚\n",
      "Decoded sentence: ä½ å¥½ï¼Œæ¸ºå°çš„ï¼‚é±¼ï¼‚\n",
      "\n",
      "-\n",
      "Input sentence: äººçš„çœ¼ç›æœ‰5.76äº¿åƒç´ ä½†å´ç»ˆç©¶çœ‹ä¸æ‡‚äººå¿ƒã€‚ã€Œè½¬ã€\n",
      "Decoded sentence: è¿™ä¸ªéƒ½æ˜¯å“ªé‡Œçš„å§ï¼Ÿå¥½æƒ³çœ¼ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: å¥½åƒååŠ¨æ´¾ä»¬éƒ½ä¸åœ¨è¿™é‡Œï¼Ÿ\n",
      "Decoded sentence: ä½ å°±æ˜¯æˆ‘å–œæ¬¢ä¸ä¸Šåˆ«äººçš„ç†ç”±\n",
      "\n",
      "-\n",
      "Input sentence: å†œå¤«å±±æ³‰å³è¾¹æ˜¯å‡çš„ï¼Œå¤§å®¶è½¬å‘å‘Šè¯‰èº«è¾¹çš„æœ‹å‹ã€‚\n",
      "Decoded sentence: æ—©è¢«å†œå¤«å±±æ³‰è¾Ÿè°£äº†ï¼Œä¸¤ä¸ªéƒ½æ˜¯çœŸçš„ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä¸å»åˆ»æ„é€ ä½œè‡ªå·±çš„å¿ƒè‡ªç„¶è‡ªåœ¨éšæ€§è€Œå¤©çœŸ\n",
      "Decoded sentence: æ˜¯çš„ä¸–ä¸Šçš„å¤©æ°”å¾ˆå¥½æœ‰é‚£ä¹ˆå¤š\n",
      "\n",
      "-\n",
      "Input sentence: å·´è¨å®˜æ–¹å®£å¸ƒé˜¿æ ¹å»·äººé©¬è’‚è¯ºå‡ºä»»çƒé˜Ÿæ–°å¸…ï¼\n",
      "Decoded sentence: æˆ‘æœ‰æˆ‘ä¹Ÿä¸å°æœ‹å‹çš„ä¸€ç‰‡å°æˆ‘é‡Œå“ˆå“ˆ\n",
      "\n",
      "-\n",
      "Input sentence: å¤šå…³æ³¨æ–°ç”µå½±ï¼œè‡´å‘½é—ªç©ï¼ğŸ’“ğŸ’“\n",
      "Decoded sentence: ä¸ªæœˆ3çš„é‚£æ˜¯ä¸ªçˆ±äººä¸€ä¸‹\n",
      "\n",
      "-\n",
      "Input sentence: ä¸‰å³¡å¤§åè´¨é‡å¦‚ä½•ï¼Ÿè¯¡å¼‚ã€‚åˆ†äº«å›¾ç‰‡\n",
      "Decoded sentence: æ˜¯è¿™æ ·çš„ï¼Œèƒ½ä¸èƒ½åšä¸€ç‰‡å¥½çš„ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: è€å¸ˆæ”¹åˆ°è¿™ä»½ç­”é¢˜å¡çš„æ—¶å€™ï¼Œè·³èµ·æ¥äº†ã€‚\n",
      "Decoded sentence: å“ˆå“ˆã€‚æˆ‘ä¹Ÿä¸æ•¢è¯´å»æŸ¥\n",
      "\n",
      "-\n",
      "Input sentence: ä¸–ä¸Šæœ€å¹¸ç¦çš„äº‹ï¼šåè„¾æ°”çš„å¥¹é‡åˆ°å¥½è„¾æ°”çš„ä»–ï¼Œä»–å´çˆ±ä¸Šäº†å¥¹ã€‚\n",
      "Decoded sentence: è¿™æ˜¯ä¸ªäººï¼Œç°åœ¨æˆ‘ä¸å¯¹é¢ã€\n",
      "\n",
      "-\n",
      "Input sentence: æ®è¯´ï¼Œè¿™æ˜¯å¸ƒæ‹‰å¾·çš®ç‰¹å†™ç»™å¦»å­çš„ä¿¡â€”â€”ã€Šçˆ±çš„ç§˜å¯†ã€‹ã€‚\n",
      "Decoded sentence: è¯´æ˜¯æ¶ˆé˜²è½¦è¿›ä¸å»ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: åœ¨é£å¾€å°¼æ³Šå°”çš„æœºç¨‹ä¸€å£æ°”çœ‹å®Œã€‚\n",
      "Decoded sentence: æˆ‘è§‰å¾—ä¸Šçš„æ‰æ˜¯æœ€æ£’çš„\n",
      "\n",
      "-\n",
      "Input sentence: æ®è¯´æ˜¯äºŒå¹´çº§çš„æ•°å­¦é¢˜ä½ ä¼šå—ï¼Ÿã€Œè½¬ã€\n",
      "Decoded sentence: è¯´åˆ°åº•ï¼Œæå¤§éœ„äººå“æ²¡æœ‰åº•\n",
      "\n",
      "-\n",
      "Input sentence: æ³•ç½‘å¥³å•å†³èµ›æå¨œVSæ–¯é½äºšæ²ƒå°¼CCTV5è§†é¢‘ç›´æ’­ï¼šalink\n",
      "Decoded sentence: å¥½å¯çˆ±å•Šï¼Œä»¥åä¹Ÿæ‰¾åƒé‚£ä¹ˆç”Ÿçš„\n",
      "\n",
      "-\n",
      "Input sentence: ä¹ä¸è™½ç©·ä½†æœ‰äººæ ¼ï¼ŒçŒªç‹—ä¸å¦‚ç•œç”Ÿæ˜¯ä¹Ÿï¼\n",
      "Decoded sentence: è¿™åˆæ˜¯é‚£ä¸ªç‹—å¨˜å…»çš„ï¼Œéª‚å·²å‡ºå£ï¼Œå¯¹ä¸èµ·è¿™ä½ç•œç”Ÿçš„æ¯äº²äº†ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å„ç§å¤±è¯¯ï¼Œä½ ä»¬æ„Ÿå—ä¸€ä¸‹ã€‚\n",
      "Decoded sentence: ç¥é¾™ï¼Œä¾ aå°rï¼Œï¼Œè¦ä¸ç»™æˆ‘æ¬¡ä¸ªè¡¨æƒ…ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: åƒæ³¡é¢çš„æœ€é«˜å¢ƒç•Œï¼ä½ æœ‰æœ¨æœ‰ï¼\n",
      "Decoded sentence: å¤šæ”¾å®‰çš„æ—¥ï¼æƒ³æƒ³è¦ä¸€å®š\n",
      "\n",
      "-\n",
      "Input sentence: è¯ºåŸºäºšLumia710ç»„æˆçš„å¤šç±³è¯ºï¼Œæƒ³ä¸æƒ³æ¨å€’TAï¼Ÿ\n",
      "Decoded sentence: æƒ³æ¨å€’TAï¼Œå†é€æˆ‘ä¸‰ä¸ªé¢œè‰²çš„å°±å¤Ÿäº†ï¼\n",
      "\n",
      "-\n",
      "Input sentence: è¯·å„ä½æœ‹å‹ä¸è¦æŠŠæˆ‘åˆ—å…¥è‡ªåª’ä½“.è°¢è°¢.\n",
      "Decoded sentence: æ˜¯ç”·çš„äººï¼Œæˆ‘ä¸åƒç”Ÿä¸­ï¼Œå“¥\n",
      "\n",
      "-\n",
      "Input sentence: å¶ç§‰æ¡“åˆšåˆšç¤ºèŒƒäº†ä¸€ä¸‹ã€Œè½¬éŸ³è½¬åˆ°åã€ã€‚å£°çº¿æŒºæ£’ã€‚\n",
      "Decoded sentence: æ²¡æœ‰GDï¼Œï¼Œæ•…åœ°dè¦ä¸å—gå§ï¼Œ\n",
      "\n",
      "-\n",
      "Input sentence: ç«¥é‹ä»¬ï¼Œå’±ä»¬ä¸€èµ·è¿‡å…­ä¸€å–½ğŸ˜ğŸ˜ğŸ˜\n",
      "Decoded sentence: æˆ‘ä¹Ÿåœ¨å¤©æ²³åŸé™„è¿‘å“ˆå“ˆå“ˆæœ€çŸ¥é“æœ‰äº›äººé™ªä¸å¼€å¿ƒåœ¨çœ‹ä¹‹åã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å¥½æ€€æ‹çš„å®¿èˆç”Ÿæ´»ï¼Œæœ‰åŒæ„Ÿçš„è½¬å§ï¼ï¼ˆviaé™ˆéªåŸºï¼‰\n",
      "Decoded sentence: çœŸæƒ³çœ‹ä¸€åŠæ˜¯ç¾å¥½çš„ï¼Œå®ƒï¼Œæˆ‘ä»¬1013æŠ¥ä¸€æ ·ç”Ÿã€‚\n",
      "\n",
      "-\n",
      "Input sentence: æ®å¤®è§†åˆšåˆšæŠ¥é“ï¼Œç¥å…«é£èˆ¹å‘å°„æ—¶é—´ç¡®å®šä¸ºä»Šæ—¥5æ—¶58åˆ†10ç§’ã€‚\n",
      "Decoded sentence: ç¥å…«å¨æ­¦ï¼Œåç­‰å‘å°„\n",
      "\n",
      "-\n",
      "Input sentence: æ¬ è‡ªå·±çš„æ—…è¡Œï¼Œæœ‰ä¸€å¤©ï¼Œä¸€å®šè¦è¿˜ç»™è‡ªå·±ï¼\n",
      "Decoded sentence: è¿™ä¸ªè¯´æˆ‘çš„æ—¥äº†ç”Ÿæ´»\n",
      "\n",
      "-\n",
      "Input sentence: æœ‰å¤šå°‘äººï¼Œè¿˜è®°å¾—å½“å¹´å­¦æ ¡çš„æ ¡è®­çš„ï¼Œè¯·ä¸¾æ‰‹ï¼\n",
      "Decoded sentence: å¾—åˆ°å­¦Â·Â·Â·Â·ä¼šä¼šä¼šè¢«å¾®ç¬‘ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: æ‰“è½¦ç»è¿‡ä¼¦æ•¦å¡”ï¼Œçš‡å®¤çš„ç›‘ç¦åœ°å’Œå¤„æ­»åœ°ã€‚#Weicoæ‹¼å›¾#\n",
      "Decoded sentence: è¦æ±‚æ˜¯æ–°ä¸ªå“†å•¦ï¼Œè¯•è¿‡ã€‚è¦ä¸€ä¸ªç»™è§†è§ï¼Œ\n",
      "\n",
      "-\n",
      "Input sentence: å“å‘€ä¸å…³æˆ‘äº‹ã€‚æ˜¯ç³»ç»Ÿè‡ªåŠ¨å‘é€çš„â€¦â€¦æˆ‘æ˜¯å°å€©alink\n",
      "Decoded sentence: å¤§ç‚®ï¼Œæœ‰ç‚¹èŒä¸šé“å°±çœ‹æˆ‘ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: åˆ«ä»¥ä¸ºæˆ‘è„¸å¤§ï¼Œå°±å¯ä»¥éšä¾¿ææˆ‘è„¸ï¼\n",
      "Decoded sentence: æˆåŠŸè€…æ€»æ˜¯ä¸çº¦è€ŒåŒçš„æ»¡è¶³æ—¶ä»£çš„éœ€è¦\n",
      "\n",
      "-\n",
      "Input sentence: å¾ˆå¼€å¿ƒè·Ÿä½ ä»¬èŠå¤©ï¼Œæ™šå®‰\n",
      "Decoded sentence: ä½ æ˜¯ç¿æ™ºçš„æˆç†Ÿå¥³äººã€‚çˆ±ä½ ã€‚æ™šå®‰îŒ§\n",
      "\n",
      "-\n",
      "Input sentence: è®°ä½æ¯ä¸€ä¸ªå–„å¾…ä½ çš„äººï¼Œå› ä¸ºä»–ä»¬æœ¬å¯ä»¥ä¸è¿™ä¹ˆåšã€‚\n",
      "Decoded sentence: å°æ—¶å€™ï¼Œåœ¨æ™’è°·åœºæ”¾æ˜ æŠ•å½±ç”µå½±ï¼Œæœ€æ·±åˆ»çš„æ˜¯ææ€–ç‰‡ã€Šç”»çš®ã€‹ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä»™å‰‘å°è¯´2å–å¾—ä¸é”™ï¼Œè¿™æ˜¯äº¬ä¸œçš„æ’è¡Œæ¦œï¼Œé”€å”®æ’è¡Œæ¦œç¬¬ä¸€ã€‚\n",
      "Decoded sentence: äººç”Ÿå°±åƒæ‘¸å¤´ï¼Œä½ æ°¸è¿œä¸çŸ¥é“ä¸‹isind\n",
      "\n",
      "-\n",
      "Input sentence: ä¸ºäº†iPhoneæ‰“å­—å¤§èµ›ï¼Œæˆ‘çš„æ‰‹åšäº†ä¸ªå°æ‰‹æœ¯ã€‚\n",
      "Decoded sentence: ä¸€ç‚¹æµ©ç„¶æ°”ï¼Œåƒé‡Œå¿«å“‰é£\n",
      "\n",
      "-\n",
      "Input sentence: ä¸€å®šè¦ä¹°è¿™å¼ CDï¼Œ#æéœ„äº‘#çš„ã€Šä½ çœ‹åˆ°çš„æˆ‘æ˜¯è“è‰²çš„ã€‹\n",
      "Decoded sentence: çœŸçš„å¥½ç¾å¥½çš„ä¸€ç‰‡ï¼å°è¯´\n",
      "\n",
      "-\n",
      "Input sentence: å¥½å£°éŸ³ï¼Œä¸€åœ¨å®¤å¤–å”±ç°åœºï¼Œæ€ä¹ˆå°±é‚£ä¹ˆå¤§å·®è·å•Šã€‚\n",
      "Decoded sentence: è¿™ä¸ªå–œæ¬¢åœ¨å¿ƒé‡Œçš„äººï¼Œå¥½åƒä½ è‡ªå·±çœ‹ä¸€ä¸‹ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: æœªæ¥åå¤©åœ¨æ³¢å…°ï¼Œæ‰‹æœºä¸é€šï¼Œæœ‰äº‹éº»çƒ¦ç§ä¿¡æˆ–é‚®ä»¶å§ã€‚\n",
      "Decoded sentence: è½¬çœ¼ä¸¤å¹´å‰æˆ‘ä¹Ÿåœ¨æ³¢å…°\n",
      "\n",
      "-\n",
      "Input sentence: æˆ‘è¿™ç§å£®æ±‰ï¼Œä¸€ç©¿ç»†é«˜è·Ÿé‹ï¼Œå°±å¥½åƒåœ¨æ¬ºå‡Œå¼ºæš´å®ƒã€‚\n",
      "Decoded sentence: ä¸ä¼šä¸æ˜¯ä¸æƒ³ä¸‹é‚£ä¹ˆå¤šä¸­å›½å—ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: ä»–ä»¬ä¹Ÿæ›¾æ˜¯å† å†›ï¼Œä½†ã€‚è¯·çœ‹å›¾ï¼ˆè½¬ï¼‰\n",
      "Decoded sentence: çœ‹äº†æˆ‘ğŸ’›æ‰‹æœºä¼šå‘¢ï¼Ÿ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: å·¥ä½œåœ†æ»¡å®Œæˆï¼Œä»Šå¤©è¦å›å°æ¹¾å•°ï¼åŒ—äº¬â€¢å†è§ã€‚\n",
      "Decoded sentence: è€ç½—ä»Šæ™šå»æå¿—çš„æ¼”å‡ºä¹ˆï¼Œæœ‰ç™»å°çŒ®å”±çš„è®¡åˆ’ä¹ˆ\n",
      "\n",
      "-\n",
      "Input sentence: å‡†å¤‡å¤œæˆ˜ï¼Œè¾èŒäº†ï¼Œå¤±ä¸šäº†ï¼Œæ±‚ä¿å…»\n",
      "Decoded sentence: å“‡ï¼Œæˆ‘ä¹Ÿçœ‹è¿‡ï¼Œä¹Ÿä¼šæ˜¯çˆ±äººï¼Œæˆ‘èƒ½å¤±å»è€ç„¶å’Œè¿½åä¸€ä¸ªã€‚\n",
      "\n",
      "-\n",
      "Input sentence: æŠŠç­”æ¡ˆï¼Œå˜æˆä½ å–œæ¬¢çš„æ ·å­ã€‚ï¼ˆviaä¼Ÿå¤§çš„å®‰å¦®ï¼‰\n",
      "Decoded sentence: æ˜¯å¦å°æ—¶å€™ä¹Ÿå°±åƒå•ä½ï¼Œæˆ‘å¤–äººå…¶ä»–ä¸æƒ³å·²ç»å¤±äº†ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä¸ºä»€ä¹ˆè¦å…³ç¯ä¸€å°æ—¶å‘¢ï¼Ÿå‰©ä¸‹57åˆ†é’Ÿåšä»€ä¹ˆï¼Ÿ\n",
      "Decoded sentence: å½“ç„¶æ˜¯é»‘å´ä¸€æŠ¤å®¶çš„é­‚ï¼Œç„¶åæ˜¯ååä¸€ä¸ªåŸåè€è´æ‰æ˜¯å¤šã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä¸€ç¯‡æ—¥è®°ï¼Œå¤šä¹ˆè‡ªå¾‹çš„å°ç«¥é‹ï¼Œè®©äººå†…ç‰›æ»¡é¢å‘€â€¦â€¦\n",
      "Decoded sentence: è¿™äººè¯´å¾—è¿™ä¹ˆåšäº†ï¼Œä»¥åä¼šä¸å¯¹å•Š\n",
      "\n",
      "-\n",
      "Input sentence: ä»Šå¤©ä¸¤å®¶ä¸­å›½å…¬å¸IPOå–æ¶ˆã€‚å¦‚æœæˆ‘æ²¡å¼„é”™çš„è¯ã€‚\n",
      "Decoded sentence: è¿™æ˜¯è¦å¿ƒæƒ…ã€‚æˆ‘ä¹Ÿä¸ä½åˆ°å®ƒç­ï¼Œè¿™ä¸ªæ™š\n",
      "\n",
      "-\n",
      "Input sentence: è¿‘å¹´æœ€å–œæ¬¢çš„ä¸¤å¥è¯—ï¼šä»–ä»¬æ‘§æ®‹èŠ±æœµï¼Œä»¥ä¸ºèƒ½é˜»æ­¢æ˜¥å¤©çš„åˆ°æ¥â€¦â€¦\n",
      "Decoded sentence: å“ˆå“ˆï¼Œè¿™æ˜¯æ€ä¹ˆæ¸¸çš„è±†è…æ¸£å·¥ç¨‹å•Š\n",
      "\n",
      "-\n",
      "Input sentence: ç‹—å®å®çš„ä¸€å¤©ï¼Œå¤ªå‚¬æ³ªäº†ï¼æ…å…¥â€¦â€¦ã€Œè½¬ã€\n",
      "Decoded sentence: ä¸èƒ½å¤ªä¸ç”¨äº†ä¸€åªæ˜¯è€ç‹è¯´è¿™æ ·è¯´\n",
      "\n",
      "-\n",
      "Input sentence: #Lenså¤œè¯#ä½ å¹³å¸¸å–œæ¬¢æ”¶é›†/çè—________________\n",
      "Decoded sentence: æˆ‘ä¹Ÿä¸ç›¸ä¿¡ä½œå®¶ä¼šä¸è¿‡å»çš„ä¸»è¦è¿˜ç»™æˆ‘å§\n",
      "\n",
      "-\n",
      "Input sentence: éš¾å¾—çš„æ—©é¥­å°±æ¥è¿™ä¸€å£ã€‚\n",
      "Decoded sentence: è€éƒ‘å‘è¿™ä¸ªæœ‰æ„ä¹‰å—ï¼Ÿä¸€åªè¦æ‰“å¤©æ¯”ï¼\n",
      "\n",
      "-\n",
      "Input sentence: æœ‹å‹ä»¬æ—©ä¸Šå¥½ï¼Œä»Šå¤©çš„ç©ºæ°”è´¨é‡ã€‚\n",
      "Decoded sentence: çœŸå¿ƒçš„ã€‚ç°å®éƒ½æ˜¯æœ‰äººå—ï¼Ÿè¿™æ ·åˆæœ‰ä¸€ä¸ªäººã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä¸»äººï¼Œæ•‘æ•‘æˆ‘ï¼Œå¸®æˆ‘ç¿»ä¸‹èº«ã€‚\n",
      "Decoded sentence: æˆ‘å»å¤©äº†ä¸€ä¸ªå°è®¤ã€‚ï¼\n",
      "\n",
      "-\n",
      "Input sentence: æˆ‘ä»¬æ¥#éšæ‰‹æ‹#æ ‡è¯­ä¸­å›½å§\n",
      "Decoded sentence: æ˜¯ä¸æ˜¯åœ¨æˆ‘è¿™ä¸ªæˆ‘ï¼Œæˆ‘æ€•å¤±å»äº†ä¹Ÿå¼ºå¤§çš„ææ€–ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä»–ä»¬çœŸçš„å‡†å¤‡å»ä¿æŠ¤åœ°çƒä¹ˆï¼Ÿé‚£ä¸ªè°ï¼Œè¦ä¸è¦é‚£ä¹ˆéœ²å¯Œå•Šï¼Ÿ\n",
      "Decoded sentence: å°æ—¶å€™ï¼Œåœ¨æ™’è°·åœºæ”¾æ˜ æŠ•å½±ç”µå½±ï¼Œæœ€æ·±åˆ»çš„æ˜¯ææ€–ç‰‡ã€Šç”»çš®ã€‹ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä¹°è›‹ç³•ï¼Œå°±æ˜¯è¦è¿™æ ·ä¹°ï¼è€æ¿ä¸€ä¸ª8å¯¸è›‹ç³•ï¼æ··åˆå£å‘³ï¼\n",
      "Decoded sentence: ä½ è¦æ‹¿æˆ‘çš„æ—¥æœ¬å—ï¼Œæ€ä¹ˆéƒ½è§‰å¾—é‚£ä¹ˆæ—©å‘¢\n",
      "\n",
      "-\n",
      "Input sentence: çæƒœé‚£ä¸ªæ¯å¤©è·Ÿä½ è¯´æ™šå®‰çš„äººã€‚î€°\n",
      "Decoded sentence: è¯è¯´æˆ‘å¥½æƒ³å¿˜è®°äº†èœ˜è››ç²¾æœ€åæ€ä¹ˆæ ·äº†\n",
      "\n",
      "-\n",
      "Input sentence: æ¯ä¸ªäººå¯¹ä½ å¥½ï¼Œéƒ½ä¸æ˜¯ä¹‰åŠ¡çš„ã€‚æ‰€ä»¥ï¼Œè¦çæƒœæ¯ä¸€ä¸ªå¯¹ä½ å¥½çš„äººã€‚\n",
      "Decoded sentence: çœŸæ˜¯ï¼Œä½ å›æ¥å°±ä¸ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å››äº”ä¸ªå°æ—¶é•¿é€”ï¼Œå®åœ¨æ— èŠã€‚è°æ¥èŠäº”æ¯›é’±çš„ï¼Ÿ\n",
      "Decoded sentence: æ²¡æœ‰äººé™ªæˆ‘çš„é²¸é±¼ï¼Œéƒ½æ˜¯å¯¹å¥¹\n",
      "\n",
      "-\n",
      "Input sentence: å§¥å§¥ï¼Œå°±å·®ä½ äº†â€¦â€¦#å¤§å°¸å‡¶çš„æ¼«ç”»#\n",
      "Decoded sentence: æˆ‘å®¶ç‹—ä¸Šå›æ¥äº†ï¼Œå¯ä»¥è®©æˆ‘è®¤è®¤çœŸçš„ï¼Œçœ‹ï¼Œè¿™æ˜¯ç¥ä¸€æ•ˆæœ\n",
      "\n",
      "-\n",
      "Input sentence: è¾£ä¹ˆè¾£ä¹ˆçƒ­ï¼Œä½ çš„åŸå¸‚æ­¤æ—¶æ­¤åˆ»å¤šå°‘åº¦ï¼Ÿä½ åœ¨å¹²ä»€ä¹ˆï¼Ÿ\n",
      "Decoded sentence: è€å¤§å®¶åˆšåˆšå½“æ—¥çš„ä¸œè¥¿è¿˜ä»¥è¿™å°ç”¨è´§\n",
      "\n",
      "-\n",
      "Input sentence: Imissyouï¼ŒbutIwon'tbotheryou.æˆ‘æƒ³ä½ ï¼Œä½†æˆ‘ä¸ä¼šæ‰“æ‰°ä½ ã€‚\n",
      "Decoded sentence: å“ˆå“ˆå“ˆå“ˆSmartisthenewsexyï¼\n",
      "\n",
      "-\n",
      "Input sentence: å¦‚æœä½ çŸ¥é“è¿™ä¸ªæ¸¸æˆçš„è¯çœŸæ˜¯æ­å–œä½ äº†ï¼Œæ­£å¼åŠ å…¥è€é¾„ç»„ã€‚ã€Œè½¬ã€\n",
      "Decoded sentence: å¦‚æœä½ å­¦äº†ï¼Œæˆ‘è¿˜åœ¨æˆ‘æˆ‘è¿˜æ˜¯å¯¹æˆ‘ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å¥½åƒå¾®åšå‡ºäº†ç‚¹é—®é¢˜ï¼Œè¯•è¯•çœ‹å‘å¸¦å›¾çš„å¾®åšï¼Œä½ ä»¬èƒ½çœ‹åˆ°å—ï¼Ÿ\n",
      "Decoded sentence: ä½ å°±æ˜¯ä¸æ˜¯åœ¨æˆ‘å®¶æƒ³èµ·å»æ™šåœ¨éƒ½ç‰¹æ—¶è¿˜æœ‰å¤šå¼ºçš„ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ç†Šå¸‚å•Šï¼Œä¸­åˆæ¥ç¢—èœæ³¡é¥­ç®—äº†ã€‚\n",
      "Decoded sentence: çœŸä¸æ˜¯è¿™æ ·èµ°å›½äººã€‚ç¬¬ä¸€å‘¨å…­è¿™ä¹ˆå¤šï¼Œåœ¨ä¸­å›½ä¼—\n",
      "\n",
      "-\n",
      "Input sentence: ä¸€å¤§æ—©ï¼Œ60åå’Œ80ååˆåµä¸Šäº†ï¼Œéƒ½åš·åš·ç€è¦è‡ªç”±\n",
      "Decoded sentence: æ„Ÿè§‰ç¬”è€…æ˜¯äº”æœˆå¤©çš„ç²‰\n",
      "\n",
      "-\n",
      "Input sentence: #æœ€å†…æ¶µ#ç¥å¥‡çš„ä¸­æ–‡ï¼Œä½ ä»¬æ„Ÿå—ä¸€ä¸‹\n",
      "Decoded sentence: åƒæ½˜å°æ—¶å€™ç†Ÿæ‚‰çš„é£ç‰©å§ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: æˆ‘å’Œæˆ‘çš„å°ä¼™ä¼´éƒ½æƒŠå‘†äº†\n",
      "Decoded sentence: ä¸è¦è¯´æˆ‘ä¹Ÿæƒ³è¦åœ¨è€ï¼\n",
      "\n",
      "-\n",
      "Input sentence: çŸ³å®¶åº„è¡—è¾¹æŸå°é¥­é¦†ï¼Œé‚£å¨å¼€æ€€ç•…é¥®ï¼Œç¥æˆ‘ç”Ÿæ—¥å¿«ä¹ã€‚\n",
      "Decoded sentence: çœ‹å­éƒ½åˆ«äººå¾ˆå¯çˆ±ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ç¬¬ä¸€æ¬¡åé«˜é“ï¼Œæ„Ÿè§‰ä¸é”™â€¦ï¼Œæ™šä¸Šå¾·å·ä¸‰åƒäººåœ¨ç­‰æˆ‘\n",
      "Decoded sentence: æƒ³åœ¨woftorlovaco.\n",
      "\n",
      "-\n",
      "Input sentence: æƒ³å’Œé—ºèœœä¸€èµ·æ‹ä¸€ç»„è¿™æ ·çš„å©šçº±ç…§å—ï¼Ÿ\n",
      "Decoded sentence: ä¸€ç‚¹æµ©ç„¶æ°”ï¼Œåƒé‡Œå¿«å“‰é£\n",
      "\n",
      "-\n",
      "Input sentence: ä¸–ç•Œæœ«æ—¥ï¼Œæœªæ˜¯æœ«æ—¥ï¼›æœ«æ—¥æœªæ—¥ï¼Œæ–¹æ˜¯æœ«æ—¥â€”â€”ç¦…å¸ˆèµ é’å¹´åˆå­\n",
      "Decoded sentence: ä¸€ç‚¹æµ©ç„¶æ°”ï¼Œåƒé‡Œå¿«å“‰é£\n",
      "\n",
      "-\n",
      "Input sentence: å¹´æœ«äº†ï¼Œæˆ‘å¾ˆç¼ºé’±ã€‚å’Œæˆ‘ä¸€æ ·çš„ç«¥é‹é»˜é»˜è½¬å‘ã€‚\n",
      "Decoded sentence: æœ‰äººå®¶é•¿å¾—ä¸€ç©éƒ½æ²¡æœ‰å•¦ï¼\n",
      "\n",
      "-\n",
      "Input sentence: å¾®ä¿¡æ­£åœ¨å¯†è°‹è½¬ç§»æ·˜å®å¤©çŒ«ä¼˜è´¨å•†å®¶ï¼Ÿ\n",
      "Decoded sentence: ä¸€ä¸ªäººæ´»åœ¨ä¸–ä¸Šåˆæ€ä¹ˆåšåˆ°è¿™äº›çœ‹ä¼¼ç®€å•çš„å‡ ä¸ªè¯å‘¢\n",
      "\n",
      "-\n",
      "Input sentence: å›¾ç‰‡è§£ç¦äº†ï¼Œä¸­å›½äººçš„å¿ƒä½•æ—¶è§£ç¦ï¼\n",
      "Decoded sentence: æ–°å¹´å¿«ä¹ï¼æ±‚ç¥è€å¸ˆï¼\n",
      "\n",
      "-\n",
      "Input sentence: ä»Šå¤©è€ƒæ”¿æ²»ä¸€æ¿€åŠ¨ï¼Œå·®ç‚¹æŠŠå…ˆé”‹é˜Ÿå†™æˆå…ˆé”‹ç›¾â€¦â€¦\n",
      "Decoded sentence: æˆ‘ä¹Ÿä¸å–œæ¬¢çš„ï¼Œæˆ‘è¿™ä¸ªåŠã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ç›‘æ§å½•åƒçœ‹åˆ°çš„ä¸€ç¾¤éæ³•å…¥å®¤è€…ã€‚å–µæ˜Ÿäººå¤ªç‰›äº†ï¼ï¼ˆè½¬ï¼‰OMGã€‚\n",
      "Decoded sentence: æœ‰æ—¶å€™å¹¸ç¦å…¶å®å¾ˆç®€å•\n",
      "\n",
      "-\n",
      "Input sentence: #æ²¡å“å›¾#å¤ªé»‘äº†â€¦â€¦è°æ²¡è·å¾—è¿‡æ¬§å† å† å†›ï¼Ÿ\n",
      "Decoded sentence: ä¸ºä»€ä¹ˆä¸è¦è¿™è¾¹å¯¹ç§°çš„ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: çœ‹å®Œäº†ï¼å‡†å¤‡ä¹°ä¸ªé™€èºå»ï¼\n",
      "Decoded sentence: æ˜¯ç”·çš„ä½“æ¸©ä¸æ€ä¹ˆæ­£å¸¸å“¦ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: æ—¥å’Œæ¼«ç”»ã€å…¨é›†ã€‘ç»ˆäºå¯ä»¥ä¸€æ¬¡ç¬‘ä¸ªå¤Ÿå•¦ã€‚ã€‚alink\n",
      "Decoded sentence: å¥½æœ‰çˆ±ï¼\n",
      "\n",
      "-\n",
      "Input sentence: å½“æ—¶éœæ¯”ç‰¹äººçš„å®£ä¼ æµ·æŠ¥æ˜¯ç”»ä¸Šå»çš„\n",
      "Decoded sentence: æˆ‘æ“¦ã€‚æ¯«æ— è¿å’Œæ„Ÿã€‚\n",
      "\n",
      "-\n",
      "Input sentence: â¤æµ·æµªçš„è¯±æƒ‘ï¼Œæ˜¯å®ƒå¾æœäº†ä½ ï¼Œè¿˜æ˜¯ä½ è¢«å®ƒå¾æœäº†ã€‚\n",
      "Decoded sentence: å¾ˆæœ‰æ„ä¹‰ï¼Œä¸€ç‚¹éƒ½ä¸æ— èŠã€‚è¯´æ— èŠçš„ï¼Œæ˜¯ä»–è¿˜ä¸æ˜ç™½å–æ°´çš„é‡è¦æ€§\n",
      "\n",
      "-\n",
      "Input sentence: ä»å¤§é™†åˆ°é¦™æ¸¯å·¥ä½œçš„äººä½ ä¼¤ä¸èµ·ã€‚\n",
      "Decoded sentence: è€éƒ‘ï¼Œä½ æ‰‹é…¸ä¸é…¸å•Šã€‚ä»¥åé™2ä¸ªå°æ—¶\n",
      "\n",
      "-\n",
      "Input sentence: å†ä¸å¼€å¿ƒï¼Œä¹Ÿè¦è¯•ç€ç¬‘ã€‚è‡³å°‘ä½ åŠªåŠ›ç¬‘ä¸€ç¬‘å°±ä¸ä¼šæ„Ÿåˆ°é‚£ä¹ˆéš¾è¿‡ã€‚\n",
      "Decoded sentence: å°±æ˜¯å˜›ï¼Œèƒœä¸éª„è´¥ä¸é¦ï¼æ‰æ˜¯å¥¥æ—åŒ¹å…‹ç²¾ç¥çš„å®—æ—¨\n",
      "\n",
      "-\n",
      "Input sentence: äº²ä»¬â€¦â€¦è­¦ç”¨æ–°è£…å¤‡å“¦ï¼Œæ¯åˆ†é’Ÿ6000å‘å“¦ï¼é¢¤æŠ–å§ï¼å‡¡äººä»¬ï¼\n",
      "Decoded sentence: å°±æ˜¯ï¼Œæˆ‘ä»¬æ‰“è¿ç”Ÿå‘½ä¸­å¥½ç¦»ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: è¿™æ˜¯åŒ—äº¬è¿˜æ˜¯åŒ—æå•Šï¼Ÿè€³æœµéƒ½å¹æ²¡äº†\n",
      "Decoded sentence: å¤§æµ·å°±ä¸èƒ½é‡åˆ°è£‚å“¥\n",
      "\n",
      "-\n",
      "Input sentence: 1967å¹´å¤§é™†å·¥ä¸šåœ°å›¾ï¼ŒSourceï¼šCIAç‚¹å‡»â€æŸ¥çœ‹å¤§å›¾â€œ\n",
      "Decoded sentence: æˆ‘å–œæ¬¢çš„äººæ„ŸåŠ¨ï¼Œè¿™å¥ï¼Œä½ å«ä¸æƒ³äº†é‚£ä»€çœ‹ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: æ¯”é¦–éƒ½æœºåœºæ›´é”»ç‚¼èº«ä½“çš„æ˜¯æ˜†æ˜æ–°æœºåœºã€‚\n",
      "Decoded sentence: æˆ‘æ“¦ï¼Œå°æ— èŠå’Œå°å¾·è¶…çš„è¿˜ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: è¯·è®°å¾—æ„Ÿæ©ï¼Œå› ä¸ºæ²¡æœ‰äººå¤©ç”Ÿå°±åº”è¯¥å¯¹ä½ å¥½ã€‚\n",
      "Decoded sentence: æ˜¯çš„å°çš„è½¦æ˜¯ä¸–ç•Œçš„æœ‰ä»€ä¹ˆå•Šï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: çœ‹æ¥æƒ³å‘å–µæ˜Ÿäººæ˜¯è¡Œä¸é€šäº†â†’ï¼¿â†’ã€Œè½¬ã€\n",
      "Decoded sentence: å¾ˆå–œæ¬¢æ‚¨å†™çš„è¯ï¼Œå‘µå‘µç¬¬ä¸€æ¬¡è¿™ä¹ˆé å‰ï¼Œå¼å¼\n",
      "\n",
      "-\n",
      "Input sentence: å¥½ä¹…æ²¡æœ‰æ„Ÿå—åˆ°è½æ±¤é¸¡çš„é”€é­‚ä½“éªŒã€‚\n",
      "Decoded sentence: æˆ‘æ˜¯äº‘ï¼Œé—ªç”µæ˜¯æˆ‘çš„æœ‹å‹ï¼\n",
      "\n",
      "-\n",
      "Input sentence: æˆ‘å‡†å¤‡åšå®¶å…·ç”Ÿæ„ï¼Œè¿™æ¬¾äº§å“è°çœ‹ä¸Šäº†å¯ä»¥é¢„å®š\n",
      "Decoded sentence: æ˜¯ä¸æ˜¯åœ¨æˆ‘è€é¢ã€‚æˆ‘å°±æ˜¯ä¸è¿‡ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä¹‰ä¹Œçš„æµ·é²œå¤§æ’æ¡£ï¼Œå’Œè€åŒå­¦å–é…’ï¼Œå¬æ­Œã€‚è‡´æˆ‘ä»¬é€å»çš„é’æ˜¥ï¼\n",
      "Decoded sentence: ä½ ä»¬å±…ç„¶è·‘å»å”±æ­Œäº†ï¼\n",
      "\n",
      "-\n",
      "Input sentence: #éšæ‰‹æ‹#äº”ä¸€å‡æœŸï¼Œéš¾å¾—æœ‰æœºä¼šæ¥è§¦å¤§è‡ªç„¶ï¼å¸¦ä¾„å¥³ç©å„¿ä¸€ç©å„¿ï¼\n",
      "Decoded sentence: è¿™ä¸ªå¹¿å‘Šè¯å¥½ï¼æ°¸ä¹…ç‰Œè‡ªè¡Œè½¦\n",
      "\n",
      "-\n",
      "Input sentence: åˆšç«™åœ¨çª—å‰ï¼Œæˆ‘â€”çœ¼å°±ç§è§äº†é‚£ä¸ªï¼Œå¯å¿ƒçš„å°å¦ã€‚\n",
      "Decoded sentence: äººç”Ÿè‹¦çŸ­ï¼Œåªäº‰æœå¤•ï¼\n",
      "\n",
      "-\n",
      "Input sentence: #æ—…é€”ç¾é£Ÿ#å¤§å®¶æ¥è¯´è¯´ï¼Œåœ¨ä½ çš„å®¶ä¹¡ï¼Œè¿™ä¸ªæ°´æœå«ä»€ä¹ˆï¼Ÿ\n",
      "Decoded sentence: å°±ç®—åšäº†ï¼Œæ¢¦åˆ°çš„äººçœŸå¯ä¸èƒ½ï¼Œï¼Œä½†æ˜¯é‚£æ˜¯æ£‰çš„æ¬¾æ˜¯\n",
      "\n",
      "-\n",
      "Input sentence: äº”ç§è°œä¸€æ ·çš„ç”Ÿç‰©ã€‚ï¼ˆviaçŠ¯è´±å¿—ï¼‰\n",
      "Decoded sentence: è°åœ¨è¿™é‡Œé¢ã€‚æ³•å›½èƒ½æœ‰æ¸…æ€ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: è¯•äº†ä¸‹ç‚¹ç‚¹ï¼Œå‘ç°ä¸ä¼šç”¨ã€‚\n",
      "Decoded sentence: å¥½å§â€¦â€¦Pçš„å¤ªæœ‰æ°´äº†â€¦â€¦\n",
      "\n",
      "-\n",
      "Input sentence: æ¯ä¸ªäººå‡ºç”Ÿçš„æ—¶å€™éƒ½æ˜¯åŸåˆ›ï¼Œå¯æ‚²çš„æ˜¯å¾ˆå¤šäººæ¸æ¸éƒ½æˆäº†ç›—ç‰ˆã€‚\n",
      "Decoded sentence: çœŸçš„å¾ˆè–„ã€‚æ¦‚è§‰çš„å¤ªç™½äº†ï¼\n",
      "\n",
      "-\n",
      "Input sentence: å†ä¸¤å¤©å°±æ˜¯æ–°å¹´äº†ï¼Œåˆå¯ä»¥æœ‰å€Ÿå£å¤§åƒå¤§å–:)\n",
      "Decoded sentence: å½“ç„¶æ„¿æ„äº†ï¼æ¥ä¸€ç‚¹æˆ‘è§‰å¾—æœ‰ç‚¹åšé¥­ï¼\n",
      "\n",
      "-\n",
      "Input sentence: è§£å†³æ—©æ™¨èµ–åºŠçš„æ¦‚å¿µåº”ç”¨ï¼\n",
      "Decoded sentence: ä½ å¥½ï¼æ¸ºå°æ—¶å€™å•Šï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: ä»å¬ä¸è…»åˆ°å¬ä¸å¾—ï¼Œä¹Ÿå°±åå¹´ã€‚å”‰ã€‚æ·±è¡¨é—æ†¾ã€‚\n",
      "Decoded sentence: å½“æ–°é²œçš„ç©ºæ°”æˆä¸ºå¥¢ä¾ˆå“ä¹‹åã€‚\n",
      "\n",
      "-\n",
      "Input sentence: #æ¯æ—¥ä¸€ç¥å¥#æˆ‘è¯´â€œåƒé”¤ç™¾ç‚¼å‡ºæ·±å±±ï¼Œâ€ä½ æ¥_________________ï¼Ÿ\n",
      "Decoded sentence: å°æ—¶å€™ï¼Œåœ¨æ™’è°·åœºæ”¾æ˜ æŠ•å½±ç”µå½±ï¼Œæœ€æ·±åˆ»çš„æ˜¯ææ€–ç‰‡ã€Šç”»çš®ã€‹ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: çˆ±ç´æµ·çš„æ—¥è½ï¼Œå¦ä¸€ç§é¢œè‰²çš„æµªæ¼«ã€‚\n",
      "Decoded sentence: æˆ‘å®¶ç‹—ä¹Ÿåªè¦å› ä¸ºçš„åœ°é‡Œæœ‰è¿™æ ·ç¾å¥³äººå°†å°†ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: åœ¨å›½é™…ç¡çœ æ—¥æ—©æ—©èµ·åºŠå¹²æ´»å„¿ï¼Œå…¶å®æœ¬è´¨ä¸Šå°±æ˜¯åäººç±»å’Œåç¤¾ä¼šï¼\n",
      "Decoded sentence: è¿™æ˜¯è§†åŠ›è¡¨ï¼è¯·æ±‚æå¼ æ¸…æ™°ä¸€ç‚¹çš„ï¼\n",
      "\n",
      "-\n",
      "Input sentence: ä¸€å¼ ç‹ å›¾å‘Šè¯‰ä½ ä»€ä¹ˆå«åšï¼šåšæŒå°±æ˜¯èƒœåˆ©ï¼(è½¬)\n",
      "Decoded sentence: æ˜¯å•Šï¼ä½ åœ¨å“ªé‡Œéƒ½å¾—ï¼Ÿï¼\n",
      "\n",
      "-\n",
      "Input sentence: åˆ†äº«äº†ä¸€ç¯‡æ–‡ç« ï¼šã€Šå†¬æ—¥ã€‹\n",
      "Decoded sentence: äººç”Ÿçš„éœ€è¦å½¢è±¡çš„å°Mç»ƒæ˜¯è¿™æ ·çš„\n",
      "\n",
      "-\n",
      "Input sentence: è¿™æ˜¯ä¸€å°ç®€å•çš„å°æƒ…ä¹¦ã€‚\n",
      "Decoded sentence: æ„Ÿè§‰ä¸é”™Â·Â·ä½†æ˜¯é‚£æ”¾æ¯›å·¾çš„æ¶å­Â·Â·Â·\n",
      "\n",
      "-\n",
      "Input sentence: ã€å¦‚ä½•ç§æŸ æª¬ã€‘æ°”å‘³èŠ¬èŠ³ï¼Œè‡ªå·±ç§ä¸€ç›†å§ã€‚ï¼ˆå‡ åˆ†é’Ÿç½‘ï¼‰#å°çŸ¥è¯†#\n",
      "Decoded sentence: æ²¡æœ‰GDPï¼Œä¹Ÿæ²¡æœ‰ç°åœ¨è©¹å§†æ–¯ï¼æ—¶ä»£çš„ç»ˆç»“ï¼Œæ°¸è¿œä¸å˜çš„æ˜¯æ€€å¿µï¼\n",
      "\n",
      "-\n",
      "Input sentence: ä¿æŠ¤å¥¹ä¸æ˜¯ä½ çš„ä»»åŠ¡ï¼Œè€Œæ˜¯æˆ‘çš„ã€‚------ã€Šç¢Ÿä¸­è°4ã€‹\n",
      "Decoded sentence: æ˜¯å•Šï¼ä½ é‚£é‡Œä¹Ÿä¼šè¿™æ ·å—ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: æ²¡çœ‹è¿‡å«ç¾è‰å®³ç¾çš„ç«¥é‹ç‚¹å‡»çœ‹çœ‹.\n",
      "Decoded sentence: æ²¡çœ‹ï¼Œå°±æ˜¯è¿™æ ·çš„å˜æˆã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ç”Ÿæ´»ä¸€å®šè¦äº”é¢œå…­è‰²ï¼Œä½†ç»ä¸èƒ½ä¹±ä¸ƒå…«ç³Ÿã€‚æ—©å®‰ã€‚\n",
      "Decoded sentence: ä¸æ˜¯å§ï¼Œå¤ªç”¨äº†å§ï¼Ÿå¥½äº†ä»Šå¤©ä»Šå¤©æ²¡æ¥ç£¨ç£¨çœ‹çœ‹ç€---ç—›\n",
      "\n",
      "-\n",
      "Input sentence: ã€å¾®æ¼«ç”»ã€‘è¿™æ˜¯æœ€å¹¸ç¦çš„æ—¶åˆ»ï¼æ²¡æœ‰ä¹‹ä¸€ï¼æœ‰åŒæ„Ÿçš„è¯·ä¸¾æ‰‹ï¼\n",
      "Decoded sentence: è¿™ä¸ªä¸æ˜¯åœ¨æˆ‘å®¶å­¦é‡Œä¸‹\n",
      "\n",
      "-\n",
      "Input sentence: å¼€è½¦åˆ°å¸ƒæ‹‰æ ¼åº„å›­æ¥ç©ï¼Œè®©å§‘çˆ·ç»™æˆ‘ç…§ä¸€å¼ ç…§ç‰‡ï¼Œæ„Ÿè§‰ä¸é”™ã€‚\n",
      "Decoded sentence: ä½ å¥½ï¼Œæˆ‘å–œæ¬¢ä½ æ²¡äº‹ï¼Œä½ ä»¥åæˆ‘ä¹Ÿåœ¨çš„æˆ‘å»åœ¨å»è€åˆ˜ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ç¦æ­¢ä¹°èœåˆ€ï¼Œæ˜¯ä¸ºäº†ä¿éšœå¤§ä¼šè¿›è¡Œé‡å¤§å˜é©ã€‚--é™¢é‡Œä¼ å‡ºæ¥çš„æ¶ˆæ¯ã€‚\n",
      "Decoded sentence: çš„ç¡®æ˜¯ç¾å¥³ç‰ˆã€‚å“ˆå“ˆå“ˆå“ˆ\n",
      "\n",
      "-\n",
      "Input sentence: ä¸»äººï¼Œä½ æ•´æ­»æˆ‘äº†ï¼Œå–µã€‚ã€Œå›¾è½¬ã€\n",
      "Decoded sentence: ä½ è¿˜æ˜¯æˆ‘å–œæ¬¢ä¸ä¸Šåˆ«äººçš„ä½ ç‚¹\n",
      "\n",
      "-\n",
      "Input sentence: å®è·µå†æ¬¡è¯æ˜ï¼ŒçŒ«æ¯”çŒ«ï¼Œæ°”æ­»é“¶ã€‚\n",
      "Decoded sentence: ï¼Œæ–‡åœ°æ–¹ä¾¿è¯´ä»¥è¯´äº†ä¸€ä¸ªä»€ä¹ˆå¹¸ç¦ï¼Œåƒ\n",
      "\n",
      "-\n",
      "Input sentence: ä½ å¹¸ç¦å—ï¼Ÿæ­¤æ—¶æ­¤åˆ»ï¼Œä¸€ä¸ªäººå–èŒ¶ï¼Œä¹Ÿæ²¡ä»€ä¹ˆå¥½æƒ³çš„ï¼Œç®—å¹¸ç¦å—ï¼Ÿ\n",
      "Decoded sentence: æˆ‘è®¤è¯†ï¼Œå®¶å®¶å–è¯•å•Šâ€¦\n",
      "\n",
      "-\n",
      "Input sentence: è±†ç“£é¦–é¡µçš„æ–°å˜åŒ–alink\n",
      "Decoded sentence: ä»æ¥æœ¨æœ‰ç‚¹ï¼Œå…ˆç”ŸæŠŠæ‰“å¤šå¹´å‰ã€‚åœ¨å®‰çš„ç”Ÿï¼\n",
      "\n",
      "-\n",
      "Input sentence: åˆ°è¾¾å®æ³¢äº†è¿ç»­ä¸‰ä¸ªå®¢åœºçœŸç´¯å‘€ï¼\n",
      "Decoded sentence: å¥½å¯çˆ±å•Šï¼Œä»¥åä¹Ÿç»™æˆ‘çš„å®å®ä¹°ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: åŠå…¬å®¤å¿…å¤‡çš„å–å¯ä¹åˆ©å™¨ï¼Œå¤å¤©å¿…å¤‡å•Šã€‚\n",
      "Decoded sentence: è€çˆ·å­è€çˆ¸æˆ‘çœŸå¥½ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: #chunwan#åŸºä½¬å®Œäº†å°±æ˜¯ä¼ªå¨˜ä¹ˆï¼Ÿ\n",
      "Decoded sentence: æƒ³æ¨å€’TAï¼Œå†é€æˆ‘ä¸‰ä¸ªé¢œè‰²çš„å°±å¤Ÿäº†ï¼\n",
      "\n",
      "-\n",
      "Input sentence: #2012é«˜è€ƒ#ã€åæ§½ã€‘ä»Šå¤©ä¸ŠåˆæŸè€ƒåœºå¤–ä¸€æ™¯ã€‚\n",
      "Decoded sentence: æ˜¯çš„ï¼Œæˆ‘æƒ³åœ¨æˆ‘ç”Ÿä¸èƒ½åœ¨æ˜æˆ‘è¿˜åœ¨é•¿å¤§å¤–è¿™æ ·ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å¼€å­¦ç¬¬ä¸€å¤©ï¼Œè¿è¥å•†æ ¡å›­å¹¿å‘Šå°±å¤§PKä¸Šäº†ï¼Œå¤ªæœ‰çˆ±äº†ï¼\n",
      "Decoded sentence: å°å­©å­çœ‹ä½ ï¼Œä»€ä¹ˆçœ‹ä¸»å»ï¼Œæˆ‘æ‰‹æœºåˆä¸æƒ³ä½ é‚£ä¸ªè€å©†çš„ç©ç‚¹\n",
      "\n",
      "-\n",
      "Input sentence: äººç”Ÿä¸­10ä»¶æ— èƒ½ä¸ºåŠ›çš„äº‹ã€‚\n",
      "Decoded sentence: å–œæ¬¢å¿ƒç†ã€‚è¥¿ï¼åŒ—äº¬ä¸‹æ¥äº†è¿™å°±æ›´äº†\n",
      "\n",
      "-\n",
      "Input sentence: ä»å‰æœ‰ä¸ªä¹é˜Ÿä¸»å”±ä»–çš„è£¤å­ä¸€ç›´å¾€ä¸‹æ»‘ã€‚\n",
      "Decoded sentence: å¾ˆå–œæ¬¢è¿™å¥è¯ã€‚å“ˆå“ˆã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å–˜å£æ°”å§ï¼Œè¿˜åœ¨å·¥ä½œå°å‰å¿™ç¢Œçš„äººä»¬ï¼â€”â€”terraæ—…æ¸¸åˆ›æ„å¹¿å‘Š\n",
      "Decoded sentence: äººç”Ÿå¦‚æˆï¼Œå…¨é æ¼”æŠ€ã€‚è¿™æ˜¯å¾ˆæ„æ€\n",
      "\n",
      "-\n",
      "Input sentence: Facebookä»Šæ™šä¸Šå¸‚ï¼Œå¦‚æœæ˜¯ä½ ï¼Œä½ ä¼šä¹°è¿›Facebookè‚¡ç¥¨ä¹ˆï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n",
      "Decoded sentence: æœ‰äººæ´»ç€åªæ˜¯å› ä¸ºæœªæ¥è¿˜ä¼´æœ‰å¸Œæœ›\n",
      "\n",
      "-\n",
      "Input sentence: å¼€å§‹è®¡ç®—é€‰ç¥¨äº†ï¼Œä½›ç½—é‡Œè¾¾å¾ˆå…³é”®ï¼Œç°åœ¨å¥¥å·´é©¬é¢†å…ˆ51ï¼…\n",
      "Decoded sentence: æ—©å®‰ã€‚å¥½å¥½ã€‚è¢«å„¿ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å§‘å¨˜ï¼Œä½ çœŸæ˜¯æ¡æ±‰å­ã€‚ã€Œè½¬ã€\n",
      "Decoded sentence: ä½ ä¸æ›¾ç»™æˆ‘ä¸€æ¬¡å›çœ¸ï¼Œæˆ‘å´å§‹ç»ˆåœ¨å¯¹ä½ è‡ªå·±çœ‹åˆ°ä½ ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å§—å§—æ¥è¿Ÿçš„äº¨åˆ©Â·ç±³å‹’ã€Šå—å›å½’çº¿ã€‹ã€ŠåŒ—å›å½’çº¿ã€‹\n",
      "Decoded sentence: å¥½å¯çˆ±å•Šï¼Œæ˜¯å¦‚ç°åœ¨å¼€å§‹åŸæ¥è¯´è¯¥è¿™å¤§äº†å¹²è´¹æœ‰å¤šä¹Ÿåƒäº†\n",
      "\n",
      "-\n",
      "Input sentence: ä¸€å¥è¯ä¸å’¯ã€‚é«˜è·Ÿé‹æ‰›æ¡¶è£…æ°´çš„å¥³æ±‰å­ï¼Œéœ¸æ°”å››æº¢(è½¬)\n",
      "Decoded sentence: å…¶å®ä½ ä»¬ä¸æ‡‚å¥³æ±‰å­å†…å¿ƒçš„è‹¦å•Šæ²¡æœ‰ç”·äººåªèƒ½è‡ªå·±æ‰›\n",
      "\n",
      "-\n",
      "Input sentence: 2011å¹´ä¸­å›½æœ€æ–°ææ€–å·¨ä½œï¼Œè¶…è¶Šæ—¥å¼æ³°å¼ææ€–ã€‚\n",
      "Decoded sentence: çœŸç©ï¼Œè¿™æ ·æƒ³ä»€ä¹ˆæ€»ä¼šæœ‰æ¯”ä½ å‘¢ï¼Ÿ\n",
      "\n",
      "-\n",
      "Input sentence: ä¸å¯èƒ½æ¯å¤©éƒ½ä¼šæœ‰é«˜æ½®ï¼Œè¿™å°±æ˜¯äººç”Ÿã€‚\n",
      "Decoded sentence: å“‡å¡ã€‚å¥½äº®çš„çœ¼ç›ï¼\n",
      "\n",
      "-\n",
      "Input sentence: ã€æ­¦æ±‰å…¬äº¤ã€‘æ°¸æ’çš„ç¥è¯ï¼Œä¸­å›½F1çš„å¸Œæœ›â€¦â€¦ï¼ˆè½¬å¸–ï¼‰\n",
      "Decoded sentence: æœ‰ä¸€ç§å¥‡æ€ªçš„æ„Ÿè§‰æ²¹ç„¶è€Œç”Ÿã€‚\n",
      "\n",
      "-\n",
      "Input sentence: ä¹ æ€»å—åˆ°æ¢…æ€»çš„çƒ­æƒ…æ¥å¾…ã€‚ï¼ˆRIA-Novostiï¼‰\n",
      "Decoded sentence: å“ˆå“ˆï¼Œæœ€åä¸€å¼ å¤ª2äº†ï¼\n",
      "\n",
      "-\n",
      "Input sentence: è€ƒè¯•å­¦ç”Ÿç±»å‹åˆ’åˆ†å›¾ï¼Œä½ æ˜¯å“ªä¸€å‹ï¼Ÿï¼ˆæºè‡ªç½‘ç»œï¼‰\n",
      "Decoded sentence: ä½ ä»¬å±…ç„¶è·‘å»å”±æ­Œäº†ï¼\n",
      "\n",
      "-\n",
      "Input sentence: æ—©ä¸Šå¥½ï¼Œä½ è·Ÿåˆ«äººæ‰“è¿‡èµŒå—\n",
      "Decoded sentence: æˆ‘æƒ³è¯´ï¼Œè¿™æ˜¯è¦è‚¯å®šå•Š\n",
      "\n",
      "-\n",
      "Input sentence: è¿˜èƒ½æ¥ç€åšæŒçœ‹ä¸‹å»çš„å‡¯èœœï¼Œéƒ½æ˜¯çœŸçˆ±ã€‚\n",
      "Decoded sentence: å¾ˆå–œæ¬¢è¿™æ ·é£æ ¼çš„ï¼Œæ¼‚äº®å¾ˆå¸Œæœ›æœ‰æ— èƒ½ç»™æˆ‘ä»¬ã€‚\n",
      "\n",
      "-\n",
      "Input sentence: å½“ä½ ä¸å†æœŸå¾…ä»€ä¹ˆä¸œè¥¿çš„æ—¶å€™ï¼Œä½ ä¼šå¾—åˆ°ä¸€åˆ‡ã€‚\n",
      "Decoded sentence: è¿˜æ˜¯wadiä¹ˆå¥½çœ‹çœ‹äº†å§.éŸ³ä»¬çš„æ˜¯å“ªå„¿ä¹Ÿä¸å¥½å¥³\n",
      "\n",
      "-\n",
      "Input sentence: ã€ã€Šç¯å¤ªå¹³æ´‹ã€‹å„å›½æœºç”²ã€‘ä½ è§‰å¾—å“ªä¸ªå›½å®¶çš„æœºç”²æœ€å¸…ï¼ï¼Ÿã€Œè½¬ã€\n",
      "Decoded sentence: å½“å®˜åšåˆ°è¿™æ ·ï¼Œèµ°åˆ°å“ªå„¿éƒ½éœ€è¦ä¸€å‰¯åšè„¸çš®æ‰å¾—è¡Œå“Ÿï¼\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_sample = len(encoder_input_data)\n",
    "for seq_index in range(num_sample-100, num_sample):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"LSTMresult.txt\", \"w\",encoding=\"utf8\")\n",
    "for seq_index in range(len(encoder_input_data)):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    fo.write(decoded_sentence)\n",
    "    \n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"LSTManswer.txt\", \"w\",encoding=\"utf8\")\n",
    "for seq_index in range(len(encoder_input_data)):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    fo.write(decoded_sentence)\n",
    "    \n",
    "fo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
